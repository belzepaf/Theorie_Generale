## LE RÊVE CYBERNÉTIQUE

### LES TORTUES MÉCANIQUES

En 1953 parut en Angleterre un merveilleux petit livre plein de poésie, d'électronique, d'humour et de neurologie, intitulé *The Living Brain*<sup id="a1">[1](#f1)</sup>, c'est-à-dire le « cerveau vivant ». L'auteur en était W. Grey Walter, professeur de physiologie au Borden Neurological Institute de Bristol. Sa double compétence de physicien et de naturaliste avait fait de Grey Walter un des meilleurs spécialistes de l'électro-encéphalogramme pour l'interprétation des phénomènes électriques qui accompagnent l'activité cérébrale. On lui doit une analyse de ces phénomènes qui a le mérite d'utiliser les acquisitions encore récentes de la théorie de l'infor­mation en même temps que celles de la technologie de l'automation stimulée par la recherche d'armes nouvelles au cours de la deuxième guerre mondiale.

Dans un chapitre de ce livre, *Totems, Toys and Tools* (totems, jouets et outils), Grey Walter présente l'étrange famille des machines qui sont capables d'imiter les performances de l'organisme vivant, voire de l'organisme humain.

La plus ancienne est celle qu'il appelle la *machina labyrinthea*, capable de chercher son chemin dans un labyrinthe, puis, l'ayant trouvé, de ne plus l'oublier. L'Américain Thomas Ross avait construit une machine de ce type dès 1938, et ses compatriotes R.A. Wallace et C.E. Shannon en construisirent d'autres, plus perfectionnées, en 1952. 

Le principe d'une telle machine est relativement simple. Elle est pourvue d'un premier ensemble constitué par un programme comportant une séquence d'opérations (avancer, tourner, etc.,) et d'un programme conditionnel muni d'un *feedback* de régulation qui commande l'opération à réaliser en fonction de l'effet de la dernière opération réalisée (obstacle, pas d'obstacle). Elle est pourvue d'autre part d'une « mémoire » rudi­mentaire alimentée par un *feedback* de cumulation, dans laquelle se constitue la séquence des opérations « réussies », c'est-à-dire se terminant par l'opération « avancer ». Cette séquence définit un programme­ maître que la machine suit dès son second passage dans le labyrinthe. Au premier passage, elle tâtonne et « apprend ». Ensuite, elle « sait » et ne se trompe plus.

Il y a là évidemment un schéma de type didactique, mais en réalité le programme-maître « appris » par une telle machine n'est qu'une reproduction aveugle de la séquence de décisions prises préalablement par la source (en l'occurrence humaine) qui a tracé le labyrinthe. Il suffit qu'une situation imprévue se présente (par exemple une seule modification dans le tracé du labyrinthe) pour que la machine soit obligée de reprendre son apprentissage à zéro. La situation est un peu celle de quelqu'un qui récite un texte par cœur et qui, interrompu par une circonstance extérieure, doit recommencer la séquence phonique depuis le début afin d' « enchaîner » au moment critique. Encore un cerveau vivant a-t-il la faculté d'enchaîner que ne possède pas la machine. 

Si l'on substitue un rat vivant à la machine, il lui faudra beaucoup plus de temps et de tâtonnements pour mémoriser le trajet correct et même quand il l'aura appris, il continuera à commettre des erreurs. Mais et c'est là sa grande supériorité sur la machine il sera capable, après quelques tâtonnements, de retrouver le fil de la séquence correcte même si l'on a délibérément provoqué l'erreur en modifiant le labyrinthe. D'autre part, d'expérience en expérience, il deviendra plus « malin » et améliorera ses performances, c'est-à-dire sa rapidité d'apprentissage et son aptitude à déjouer les pièges. La machine n'a pas accès à ce niveau didactique supérieur qui est celui de l'éducation par opposition à celui de l'acquisition de « connaissances » formelles.

En fait, la *machina labyrinthea* n'est qu'une variété motrice de la machine à feedback homéostatique réalisée quelque temps auparavant par William Ross Ashby<sup id="a2">[2](#f2)</sup>. A cette dernière Grey Walter donne le nom de *machina sopora* (machine dormante) et il la compare au chien ou au chat qui dort au coin du feu, ne bouge que lorsque quelque chose le gêne, et se rendort dès qu'il a éliminé l'élément perturbateur. La *machina labyrinthea* est simplement un homéostat dont l'état d'équilibre est le fonctionnement de moteurs qui lui permettent d'avancer. L'obstacle qui se présente est traité comme un élément perturbateur de cet équilibre.

C'est la technologie militaire qui a demandé des machines plus complexes et plus proches du comportement humain ou tout au moins animal. Le missile autoguidé primitif est une sorte de *machina laby­rinthea* qui cherche son chemin à travers l'invisible labyrinthe tracé par des « couloirs » d'ondes de toutes sortes un peu comme la chauve-souris le fait grâce au sonar dont l'a dotée la nature, mais s'il lui faut faire face aux manœuvres complexes et ultra-rapides du combat aérien super­ sonique, il doit être capable non seulement d'éviter l'erreur de parcours, mais de *chercher* et d'*identifier* l'objectif.

C'est ainsi qu'on en est venu à imaginer ce que Grey Walter appelle la *machina speculatrix* (la machine exploratrice). Il en énonce dans son livre l'hypothèse fondamentale, à savoir que « c'est moins la multiplicité des unités mises en jeu qui est responsable des fonctions cérébrales que la richesse de leurs interconnexions »<sup id="a3">[3](#f3)</sup>. Autrement dit, le software défini par la complexité des systèmes d'interconnexion l'emporte sur le hardware défini par le nombre des points d'émission ou de réception. 

Grey Walter énumère les fonctions que la machina speculatrix doit être en mesure de remplir :

1. L'*économie* (*parsimony*), c'est-à-dire la capacité d'éviter les tâtonnements dispendieux en temps et en énergie qu'on observe souvent dans la nature et que compense la spécialisation (donc la non-redondance informationnelle) des organes, vers laquelle tendent les organismes vivants.
2. L'*exploration* (*speculation*), c'est-à-dire la capacité de rechercher les problèmes au lieu de les subir comme le fait l'homéostat. Cette fonction suppose un *balayage* (*scanning*) permanent de l'environnement.
3. Le *tropisme positif* (*positive tropism*), c'est-à-dire la faculté d'être attirée par certains stimuli.
4. Le *tropisme négatif* (*negative tropism*), c'est-à-dire la faculté d'être repoussée par certains stimuli.
5. Le *discernement* (*discernment*), c'est-à-dire la faculté de distinguer un comportement efficace d'un comportement inefficace.
6. L'*optimalisme* (*optima*), c'est-à-dire la faculté de faire un choix qualitatif entre deux comportements possibles en réponse à un même stimulus.
7. L'*identification de soi* (*self-recognition*), c'est-à-dire la faculté de s'identifier comme différent du reste de l'environnement.
8. L'*identification mutuelle* (*mutual recognition*), c'est-à-dire la faculté pour les machines de même type de s'identifier entre elles.
9. La *stabilité interne* (*internal stability*), c'est-à-dire une modalité de la fonction homéostatique permettant à la machine de donner la priorité à sa survie et notamment à son alimentation en énergie. On reconnaît ici la « troisième loi de la robotique ».

Une telle machine a été réalisée dès 1952 par Grey Walter avec seulement deux chaînes d'éléments reproduisant grossièrement les chaînes neuro-sensorielles et neuro-motrices de l'organisme humain.

Elle a l'allure d'une tortue mécanique roulant sur des pneus et dispose :

1. d'un *système sensoriel* composé:
    - d'une cellule photo-électrique orientable: la vue,
    - d'une barre de contact qui réagit aux obstacles (objets, décli­vités) : le toucher,
2. d'un *système nerveux central* composé:
    - d'une pentode dont le courant de sortie varie selon les variations des courants d'entrée, et qui est le « cerveau »,
    - d'une triode et d'un condensateur qui font varier l'alimentation de la pentode selon les impulsions reçues de la cellule photo-électrique,
    -  de deux relais commandés par la barre de contact, qui font varier l'alimentation de la pentode selon les obstacles rencontrés,
3. d'un *système d'expression* constitué par un signal lumineux
commandé par la pentode,
4. d'un *système moteur composé* :
    - d'une roue avant directrice qu'un moteur commandé par la pentode fait pivoter et qui est solidaire de la cellule photo-électrique orientale (feedback mécanique),
    - de deux roues motrices actionnées par un moteur commandé par la pentode.

La structure du système nerveux central permet l'inscription au niveau de la triode et des relais de deux programmes conditionnels que la pentode intègre et traduit en instructions données au signal lumineux et au système moteur, Ces programmes sont les suivants:

PROGRAMME 1 (cellule photo-électrique)

| CONDITION         | SIGNAL | INSTRUCTIONS       | INSTRUCTIONS       |
|-------------------|--------|--------------------|--------------------|
|                   |        | *Roue directrice*    | *Roues motrices*     |
| 1. Obscurité      | Allumé | Pivoter rapidement | Avancer lentement  |
| 2. Lumière faible | Allumé | Arrêt              | Avancer rapidement |
| 3. Lumière forte  | Eteint | Pivoter lentement  | Avancer rapidement |

PROGRAMME 2 (barre de contact)

| CONDITION         | INSTRUCTION                                           |
|-------------------|-------------------------------------------------------|
| 1. Pas d'obstacle | Appliquer le programme 1                              |
| 2. Obstacle       | 1. Interrompre le programme 1<br>2. Alternativement : <br>    2/3 du temps phase 1 du programme 1<br>1/3 du temps phase 3 programme 1|

Le comportement de la machine peut se décrire de la manière suivante.

Dans l'obscurité et sur un terrain sans obstacle, elle avance lentement lampe allumée, en décrivant des boucles qui permettent à la cellule photo-électrique de balayer l'horizon rapidement sur 360 degrés. 

Si elle rencontre un obstacle, elle l'annonce en allumant et en éteignant alternativement sa lampe signal et cherche une issue en faisant varier régulièrement l'ampleur de ses boucles: 2/3 du temps boucles serrées (rotation rapide, marche lente), 1/3 du temps boucles larges (rotation lente, marche rapide).

Si elle perçoit une lumière faible (c'est-à-dire inférieure au seuil
fixé par le programme), elle se dirige droit vers elle en marche rapide. C'est le tropisme positif.

Si elle perçoit une lumière forte (supérieure au seuil), elle s'en
détourne, rapidement, ce qui implique qu'elle puisse se diriger vers une
lumière lointaine, mais s'en détourner quand elle arrive assez près d'elle
pour que le seuil d'intensité soit atteint. Le tropisme négatif ne joue ici
qu'en deçà d'une distance critique, phénomène qui rappelle étrangement
le comportement animal<sup id="a4">[4](#f4)</sup>.

On notera que si la charge des batteries décroît, la sensibilité de la cellule photo-électrique décroît aussi, ce qui fait que le seuil critique d'intensité de la lumière à partir duquel, dans le programme l, la machine passe de la phase 2 à la phase 3, est de plus en plus élevé. Si, en un point d'alimentation en énergie où la machine peut aller d'elle-même recharger ses batteries (par exemple une prise de courant sur laquelle elle se branche par un simple contact frontal), on place une source de lumière d'inten­sité supérieure au seuil critique, tant que ses batteries sont suffisamment chargées, la machine l'évite, mais dès que la charge de ses batteries descend au-dessous d'un certain niveau, elle se dirige droit vers elle et va se brancher. Autrement dit, quand elle a « faim », elle donne priorité à sa survie et va « manger ». Un système de relais assez simple permet de déconnecter les moteurs tant que le courant de charge reste d'une intensité assez élevée, ce qui immobilise la machine pendant qu'elle « se nourrit », mais lui permet de reprendre sa route dès qu'elle est « repue ».

Si l'on place un miroir sur son chemin, la machine se dirige vers lui, attirée de loin par le reflet de sa propre lampe signal. A un certain moment, l'intensité lumineuse du reflet devient trop forte, ce qui a pour effet de déclencher la phase 3 : la machine se détourne et éteint sa lampe signal. Mais l'obscurité revenue déclenche aussitôt la phase 1 : la lampe se rallume et la machine reprend son mouvement exploratoire. Dès qu'elle « accroche » de nouveau son reflet, le cycle recommence. On reconnaît là un *feedback* du type de l'effet Larsen avec les complications et les incertitudes (les « bruits ») ajoutées par le fonctionnement de systèmes mécaniques. Le résultat est une sorte de danse rituelle qui est le signe de l'autoidentification. Grey Walter la décrit ainsi avec un intraduisible humour: « *The creature therefore lingers before a mirror, flickering, twittering and jigging like a clumsy Narcissus.*<sup id="a5">[5](#f5)</sup> » Fasciné par ce narcissisme, il ajoute que la machine, en s'identifiant elle-même d'emblée, se montre sur ce point supérieure à beaucoup d'animaux évolués qui traitent leur reflet comme s'il s'agissait d'un autre individu. C'est ignorer le fait que le comportement de l'animal est en ce cas d'abord un comportement social: l'identification de l'autre précède et détermine l'identification de soi. Alors que la machine est enfermée dans un *feed­back* de type larsénien, l'animal, comme le rat du labyrinthe, devient de plus en plus « malin » à mesure que se répète l'expérience du miroir. Il en vient plus ou moins vite à découvrir que 1'« autre » du miroir est différent des autres « autres » et qu'il a avec lui des relations de commu­nication particulières car il est à la fois totalement inaccessible et tota­lement obéissant. C'est à partir des réponses qui sont données à ses propres signaux que l'être vivant peut en arriver à élaborer une conscience de soi. Une telle didactique socio-individuelle est hors de portée de la tortue mécanique de Grey Walter.

Cela ne l'empêche pas d'avoir éventuellement une sorte de compor­tement social. Deux ou plusieurs machines de même type ont un compor­tement d'identification mutuelle. Grey Walter le décrit ainsi: « Deux créatures du même type, attirées par la lumière l'une de l'autre, éteignent l'une et l'autre la source d'attraction dont elles sont porteuses au moment où elles vont atteindre celle dont l'autre est porteuse. En conséquence, si aucune autre source d'attraction ne se présente, plusieurs de ces machines sont incapables d'échapper les unes aux autres, mais ne peuvent non plus jamais consommer leur « désir »; vue de dos ou de côté, une autre créature semblable est simplement un obstacle. En un sens donc, une population de machines forme une sorte de communauté avec un code de comportement particulier. Quand un stimulus externe est appliqué à tous les membres de cette communauté, il est perçu indépendamment par chaque machine et la communauté éclate; donc, plus il y a d'indi­vidus, moins il y a de chances qu'aucun d'eux atteigne son but, car chaque individu trouve dans les autres des obstacles convergents »<sup id="a6">[6](#f6)</sup>.

Il est important de faire ici une remarque qui trouvera plus loin<sup id="a7">[7](#f7)</sup> son application: l'impuissance du groupe de machines telle qu'elle est décrite par Grey Walter, vient du fait que c'est un groupe « égalitaire » où il n'y a ni spécialisation, ni hiérarchie. Toutes les tortues ont la même structure et sont capables de performances identiques; elles reçoivent toutes directement les mêmes informations. II suffirait que l'une d'entre elles soit dotée d'un programme spécial stipulant qu'après un certain nombre de « rencontres », elle garde sa lampe signal allumée à demi­ puissance pour qu'elle devienne un pôle d'attraction pour les autres et se transforme en « leader » du groupe. L'information transitant par elle deviendrait prioritaire.

Il est intéressant de noter que, dès le début de son livre, Grey Walter pose le problème de l'organisation communicationnelle en prenant l'exemple de la *Home Guard* britannique en 1940, dont le comportement ressemblait un peu à celui des tortues mécaniques: « Les enthousiastes de la première heure se souviendront que nos premières escouades étaient reliées de manière parfaitement égalitaire et qu'ainsi toute information reçue par une escouade était reçue par toutes les autres. Chaque escouade avait son officier de renseignements. Pour les besoins immédiats cela paraissait un excellent dispositif, particulièrement simple. La découverte d'un parachutiste ennemi par n'importe quelle unité serait immédiatement connue de toutes; d'autre part les troupes de la garde dans leur ensemble subiraient un minimum de dommages si une escouade venait à être anéantie. Mais bientôt le nombre et la variété des tâches augmentèrent. Si chaque ordre devait aller à tous et si chaque escouade devait envoyer son information à toutes les autres sur tous les sujets, chaque membre de chaque escouade serait sans cesse en alerte, et il ne resterait personne pour recevoir les messages et agir d'après eux. Si bien que notre système spontané et enthousiaste, si redoutable qu'il ait pu être dans certains cas, dut céder la place à la traditionnelle centra­lisation militaire du renseignement et à la chaîne de commandement »<sup id="a8">[8](#f8)</sup>.

Ce qui est important, c'est que la *Home Guard* ait été capable d'évoluer et de se transformer en une armée spécialisée et hiérarchisée comme le réseau indifférencié de cellules nerveuses de la méduse a évolué au cours des millénaires et s'est transformé chez les mammifères supérieurs en un système nerveux hautement spécialisé et hiérarchisé. C'est évidemment cette capacité d'apprentissage qui manque à la *machina specufatrix* originelle. Pour reprendre des termes déjà employés, la machine est incapable de nég-entropie. Cela veut dire qu'elle est incapable de créer la différenciation.

Nous verrons plus loin la dernière des machines de Grey Walter, la *machina docilis* ou machine éducable. Il convient cependant de s'arrêter un moment sur une ambiguïté de son propos.

En mentionnant la « centralisation du renseignement » et la « chaîne de commandement .» comme les deux structures capables de remédier à l'impuissance qui frappe un trop grand nombre d'unités interconnectées de manière égalitaire, il semble établir une sorte d'équivalence entre la *spécialisation* et la *hiérarchie*. Or il apparaît que c'est là un postulat tout à fait gratuit. Une hiérarchie suppose un apport d'information de la part d'un « preneur de décisions » (*decision maker*), une spécialisation suppose un simple traitement combinatoire de l'information par un « élaborateur de tactique » (*policy maker*) qui ne transmet à ses organes d'exécution rien d'autre que ce qu'il a reçu de ses organes de rensei­gnement. Une armée ne peut se passer d'une hiérarchie : même si elle est entièrement automatisée, il faut une source humaine pour prendre la décision d'appuyer sur le bouton.

Dans une machine, il en va autrement. La *machina speculatrix* de Grey Walter possède avec la pentode un organe spécialisé de centra­lisation du renseignement, mais ce n'est pas un poste de commandement : tout le flux d'information qui circule dans la machine et détermine son comportement vient de l'extérieur grâce à ce que Grey Walter appelle « un *feedback* » avec l'environnement. C'est un système réflexe tel qu'en possèdent tous les organismes vivants. Un véritable cerveau a d'autres exigences. Ce sont ces exigences qu'essaie de satisfaire artificiellement la cybernétique.

### MAITRES ET ESCLAVES

Platon emploie le mot de *kubernêtikê* pour désigner l'art du pilotage, puis par extension l'art du gouvernement. En 1834, André-Marie Ampère, essayant dans son *Essai sur la philosophie des sciences* d'établir une nomenclature binaire des diverses branches du savoir, modernisa le terme en cibernétique pour désigner la partie de la science politique qui traite de l'exercice du gouvernement.

On notera que dans l'un et l'autre cas, la métaphore implicite du pilote se réfère à une idéologie politique hiérarchisante dont la longue tradition remonte aux origines sociales du monothéisme. Le gouvernant, c'est « l'homme à la barre », le « maître à bord », le preneur de décisions suprême. Toute information émane de lui: il est le substitut de la divinité.

Le terme proposé par Ampère n'eut guère de succès et tomba dans l'oubli (Littré le mentionne comme une curiosité archaïque), mais dans la première moitié du xx" siècle, l'idéologie du pilote (*duce*, *Fûhrer* , *vojd* , *leader* ... ) se développa avec le sinistre succès qu'on connaît.

Il semble que Norbert Wiener<sup id="a9">[9](#f9)</sup> n'ait été conscient ni de l'initiative d'Ampère, ni de ses implications politiques lorsqu'en 1948 il réinventa le mot de *cybernetics* dans son livre *Cybernetics : Or Control and Commu­nication in the Animal and the Machine*<sup id="a10">[10](#f10)</sup>. Ce livre, publié par le prestigieux Massachusetts Institute of Technology (M.I.T.), possède­ dans la science de l'information au moins autant d'importance que les articles de Claude E. Shannon dont il est le contemporain.

Norbert Wiener avait alors 54 ans. Cet Américain tranquille, ancien enfant prodige des mathématiques, avait, comme beaucoup de ses contemporains (et en particulier Grey Walter en Angleterre), eu affaire pendant la guerre aux problèmes de la détection et du radioguidage des avions et des missiles. C'est pourquoi il est compréhensible que ses idées portent la marque de l'organisation hiérarchique militaire. En gros, les systèmes que décrit Norbert Wiener comprennent des organes maîtres qui intègrent l'information et prennent des décisions, et des organes esclaves, les servomécanismes (du latin *servus*, esclave), qui exécutent les instructions qui leur sont données et sont maintenus dans l'obéissance par des *feedbacks* négatifs de type homéostatique.

Le livre de Wiener fut un best-seller international. Son mérite, mais aussi son danger, était qu'il apportait une description neuve d'un ensemble de phénomènes, jusque-là non reliés entre eux, dans un grand nombre de domaines de la connaissance. Le concept même de cybernétique est à la fois hautement généralisateur et hautement vulgarisateur. Comme le fait remarquer J.R. Pierce, si l'on demandait de nos jours à un savant quelconque physicien, biologiste, sociologue, économiste s'il fait de la cybernétique, il commencerait par s'interroger sur les intentions et la compétence de son interlocuteur, et s'il décidait qu'il a affaire à un profane sans arrière-pensée, incapable d'assimiler les notions scientifiques de sa spécialité, il répondrait probablement oui<sup id="a11">[11](#f11)</sup>.

En fait, à partir des années 50, la notion de cybernétique a eu un multiple destin. On en trouvera une excellente analyse dans l'article que M.E. Maron lui a consacré dans l'*International Encyclopedia of the Social Sciences*<sup id="a12">[12](#f12)</sup>.

D'abord d'une manière assez générale et particulièrement en Union Soviétique à partir de 1955, la cybernétique a été acceptée comme un terme générique couvrant l'ensemble des technologies de l'automation, des systèmes de communication et des méthodes de traitement de l'infor­marion. Ce n'est pas une science spécifiquement constituée, mais plutôtune pratique pluridisciplinaire tendant à modifier quantitativement les relations de l'homme avec son milieu. Cette modification quantitative se traduit par une modification qualitative dans la mesure où les fonctions d'exécution sont déléguées à des mécanismes, libérant ainsi l'homme ou le groupe pour les fonctions supérieures où il est irremplaçable. C'est ainsi que le système de régulation thermique des animaux à sang chaud a libéré les mammifères du souci de s'adapter à la température de l'envi­ronnement et leur a permis d'évoluer vers un fonctionnement du système nerveux où l'intelligence, créatrice d'information, prend le pas sur le réflexe, simple transcodage de l'information. Un tel schéma peut être reproduit mécaniquement<sup id="a13">[13](#f13)</sup>.

Il y a là un choix idéologique à la fois matérialiste et humaniste. On peut lui opposer l'idéologie idéaliste et aliénante de la pensée structu­raliste qui s'est développée surtout en France entre 1950 et 1970, et dont il sera question plus loin. Le structuralisme, d'ailleurs abusivement nommé ainsi, tend à faire de la cybernétique une science générale des organi­sations. Nous avons montré comment on peut effectivement décrire - du moins partiellement un mécanisme comme celui des salaires et des prix au moyen du modèle de l'homéostat. La chose devient absurde à partir du moment où l'on entend non seulement décrire, mais expliquer. C'est alors le règne du raisonnement par analogie, c'est-à-dire par métaphore: très exactement le contraire d'un raisonnement scientifique. Toute cette « science » cybernétique repose sur l'hypothèse irrationnelle qu'il existe des «atomes de structure », c'est-à-dire des unités élémentaires d'information qui sont des « boîtes noires » définies par une entrée et une sortie. La mesure des valeurs d'entrée et de sortie fait apparaître des fonctions qui constituent les unités en organismes. La notion de boîte noire est, certes, très féconde, mais que signifient des mesures qui pré­tendent ignorer la nature physique des organes en cause, c'est-à-dire la nature physique des valeurs à mesurer? La cybernétique apparaît alors comme une sorte de jeu de meccano souvent trompeur quand il prétend simuler la réalité, toujours dangereux quand il prétend étendre ses approximations à la vie psychique ou à la vie sociale.

En fait cette cybernétique échoue devant les exigences du cerveau humain. Incapable, pour le moment tout au moins, d'en simuler l'impré­visibilité, elle l'assimile à l'aléatoire en l'asservissant aux lois qui régissent les grands nombres. C'est ainsi qu'une mesure comme celle qui est faite lors des sondages d'opinion est indûment assimilée à l'expression d'une volonté ou d'un choix.

Le comportement humain considéré objectivement paraît aléatoire, mais il ne l'est pas dans la mesure où l'observateur peut s'attendre à voir se produire « n'importe quoi », mais où la source humaine ne fait jamais « n'importe quoi ». Le fameux « démon de Maxwell » détruit par un acte de volonté de type humain la répartition aléatoire des molécules de gaz<sup id="a14">[14](#f14)</sup>. L'aléatoire peut toujours se maîtriser à la longue et les machines de traitement automatique de l'information comme les ordi­nateurs sont tout à fait capables de réaliser ce travail. Mais si on leur demande d'exercer la même maîtrise sur l'imprévisibilité humaine, ils sont conduits à valoriser ce qu'il y a d'aléatoire (parce que mécanique) dans le comportement humain et à effacer tout ce qu'il y a d'exercice de la liberté, c'est-à-dire de véritablement humain. En ce sens, on peut dire que l'évaluation quantitative de l'opinion obtenue grâce au suffrage universel apprend sur la volonté des électeurs tout ce qui est inessentiel, mais rien de ce qui est irremplaçable.

Dans une excellente nouvelle intitulée *Foot's Mate* (*Le pion du fou*), l'écrivain de science-fiction Robert Sheckley a donné une excellente illustration de cette impuissance de la « science » cybernétique<sup id="a15">[15](#f15)</sup>. Deux flottes spatiales dont la stratégie est commandée par des ordinateurs, sont face à face et n'engagent pas le combat, car, en intégrant toutes les données et en évaluant tous les facteurs aléatoires, les deux ordinateurs adverses ont déjà déterminé d'une manière absolument rigoureuse laquelle des deux flottes remportera la victoire. Aucun des deux amiraux ne veut livrer une bataille inutile. Dans la flotte « vaincue », cette situation crée une situation psychologique intenable: un à un, officiers et hommes perdent la raison, jusqu'au moment où un navigateur, devenu complè­tement fou, se met à actionner les commandes manuelles au gré de comptines qui remontent de son enfance. Les ordinateurs stratèges sont complètement désemparés car ce n'est là ni un facteur rationnel qu'on peut extrapoler; ni un facteur aléatoire qu'on peut réduire à des probabilités. Et, bien entendu, c'est la flotte « vaincue » qui remporte la victoire. Plus modestement, pour un joueur d'échecs novice qui veut battre un champion (et certaines machines sont de redoutables champions), le meilleur moyen n'est ni de tenter de rivaliser d'ingéniosité avec l'adversaire, ni de jouer au hasard, mais de jouer selon un dessein (en anglais *pattern*) à la fois cohérent et irrationnel.

Nous reviendrons plus loin sur l'intérêt qu'il y aurait à substituer la notion concrète de *pattern* à la notion abstraite de structure. Contentons-nous pour le moment de constater qu'une « science » cyber­nétique débouchant sur une technologie ou, pire encore, une politique, est par définition mutilante.

Norbert Wiener et ses élèves directs s'en sont parfaitement rendu compte. Wiener lui-même a passé les dix dernières années de sa vie à dénoncer les dangers de la cybernétique ainsi comprise. Pour lui, la cybernétique est avant tout un langage permettant d'établir des dialogues entre des domaines scientifiques très éloignés les uns des autres. En s'en tenant à la description des phénomènes au moyen de ce langage, on utilise les analogies, mais on ne raisonne pas sur elles et surtout on ne les prend pas pour des liens rationnels. .Nous avons vu que le langage de la thermodynamique a permis d'éclairer rapidement et efficacement les problèmes de la théorie de l'information, mais nous avons vu aussi que ce langage a des limites et que si l'on veut le pousser trop loin, on aboutit à une impasse.

L'entreprise de Wiener était beaucoup plus vaste et plus globale. C'est grâce à elle qu'a pu être menée à bien la grande aventure de l'ordi­nateur, comme il le raconte dans son roman *The Tempter*. Mais le titre est symbolique : *Le Tentateur*. Tout le monde n'a pas su résister à la tentation<sup id="a16">[16](#f16)</sup>.

Après la grande foire à la quincaille des années 1950-1970, il a bien fallu reconnaître que l'ordinateur est une caisse enregistreuse de génie, mais rien de plus qu'une caisse enregistreuse. Il a bouleversé notre vie, mais il ne l'a pas vraiment changée. Ses deux grandes fonctions, la mémoire et le calcul, nous ont permis de desserrer l'étau chronologique. Le document informatique prend au piège et rend indéfiniment dispo­nible une quantité d'événements incommensurablement plus grande que le document écrit traditionnel. D'autre part une opération relativement complexe comme <a href="https://www.codecogs.com/eqnedit.php?latex=\sqrt{256^3*0,245^4}=245,86" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\sqrt{256^3*0,245^4}=245,86" title="\sqrt{256^3*0,245^4}=245,86" /></a> devient aussi simple que 2 + 2 = 4. On notera que, dans le deuxième cas, l'opération étant posée, la réponse 4 n'apporte aucune information à qui connaît la table d'addition, l'équivalence entre les deux termes étant perçue instantanément, alors que dans le premier cas, même si un calculateur exercé peut rapidement évaluer l'ordre de grandeur de la réponse, cette dernière est dans l'immédiat totalement imprévisible et donc chargée d'information pendant un temps plus ou moins long : quelques minutes si l'on dispose d'une règle à calcul, beaucoup plus longtemps si l'on s'en tient au crayon et au papier. Cette création d'information périssable et liée à la durée est une des caractéristiques de la performance de la machine informatique. Il est des cas, d'ailleurs, où les calculs à effectuer sont tellement complexes qu'ils prendraient plusieurs centaines d'années à un esprit humain muni de ses outils ordinaires (par exemple la recherche des nombres premiers ou des décimales de *pi*) et en ces cas, on peut considérer que l'ordinateur est *pratiquement* créateur d'information.

C'est ainsi que le. mathématicien William Shanks passa quinze ans de sa vie, entre 1858 et 1873, à calculer les décimales de *pi* jusqu'à la 707e en commettant d'ailleurs une erreur fatale vers la 500e<sup id="a17">[17](#f17)</sup>. Trois quarts de siècle plus tard, en 1949, le cerveau électronique Eniac<sup id="a18">[18](#f18)</sup> mit soixante-dix heures pour atteindre la 2035e décimale et en 1955, un ordinateur plus perfectionné arriva à la 10 017e décimale en trente-trois heures.

Mais on s'aperçut vite que plus on améliorait les performances du *hardware*, plus il fallait diversifier et développer les interventions du *software* : collecte de l'information, analyse, codage, programmation, décodage, interprétation. Quelles que soient ses performances, l'ordi­nateur reste intellectuellement un crétin moins capable d'initiative ou d'invention qu'une bactérie. Quels que soient les perfectionnements dont on le dote, il ne peut modifier ses programmes que conformément à d'autres programmes: le cycle répétitif peut se compliquer à l'extrême, mais il reste répétitif. Autrement dit l'ordinateur ne prend pas le risque d'un « saut » intellectuel qui déroge au programme en prenant des raccourcis permettant des économies d'information non pertinente.

Cela veut dire qu'il n'est capable d'apprendre que par impression de données dans sa mémoire ou par tâtonnement, en enregistrant la séquence des « échecs » et des « succès », comme le fait la *machina laby­rinthea* de Grey Walter. Toute la question est de savoir si un dispositif mécanique est capable d'apprendre par *association*, c'est-à-dire d'établir de lui-même des liaisons non préalablement programmées entre des stimuli et des données enregistrés par lui, élaborant ainsi de nouveaux programmes mieux adaptés à ses relations avec son environnement.

### LE MODÈLE DE PAVLOV

A partir de 1863, un jeune professeur de physiologie de l'Université de Moscou, du nom de Ivan Mikhaïlovitch Sechenov<sup id="a19">[19](#f19)</sup>, publiait une série d'articles sur le rôle et le mécanisme du réflexe dans la vie psychique. Ayant travaillé en Allemagne et en France, notamment au laboratoire de Claude Bernard, Sechenov présentait un certain nombre de thèses dont les principales sont les suivantes :

1. Il n'y a pas de démarcation entre les actes somatiques et les phénomènes psychiques.
2. Actes volontaires et pensées sont pour la plus grande partie des réflexes.
3. Le réflexe est un phénomène associatif.
4. Les perceptions et les idées naissent de l'association et de l'inté­gration de réflexes par la médiation du système nerveux central.
5. La presque totalité des pensées et des idées est due à un appren­tissage des relations de l'organisme avec l'environnement, l'hérédité ne jouant qu'un rôle minime.

Ce matérialisme avoué qui porte la marque du positivisme occi­dental devait trouver en Russie, puis plus tard en Union Soviétique un terrain particulièrement favorable.

Le plus illustre des successeurs de Sechenov bien qu'il n'ait que tardivement reconnu son influence fut Ivan Petrovitch Pavlov<sup id="a20">[20](#f20)</sup> qui, au moment de la Révolution de 1917, était déjà depuis vingt-cinq ans professeur de physiologie à l'Académie rnédico-chirurgicale de Saint­ Pétersbourg. En 1924, l'Académie des Sciences de l'Union Soviétique créa pour lui près de Leningrad, dans une localité qui porte maintenant le nom de Pavlovo, un Institut de Physiologie qui est devenu un des plus importants centres de recherches du monde dans les domaines de la neurologie, de la psychologie expérimentale, des sciences de l'éducation et surtout de l'étude du comportement.

L'apport inestimable de Pavlov à la science est son étude inlassable, étendue sur plus de soixante ans, du *réflexe conditionné*. C'est en 1903 que Pavlov a pour la première fois décrit ce phénomène dans sa communi­cation au XIVe Congrès Médical International de Madrid. Il distingue d'une part les réflexes inconditionnés qui font correspondre une réponse déterminée à un stimulus déterminé selon un programme préétabli (et qui sont innés quand le programme fait partie de l'héritage génétique), d'autre part les-réflexes conditionnés qui font artificiellement correspondre une réponse déterminée à un stimulus non préalablement programmé. La loi fondamentale qu'il a énoncée est qu'un stimulus quelconque peut susciter la réponse désirée s'il a été administré une ou plusieurs fois *en même temps* que le stimulus correspondant à cette réponse dans un réflexe inconditionné. C'est ainsi que dans l'expérience de base de Pavlov, l'apparition de nourriture provoque la salivation chez un chien. Si un signal sonore ou lumineux accompagne un certain nombre de fois l'appa­rition de la nourriture, ce signal finit par provoquer à lui seul la salivation.

Pavlov a énoncé un certain nombre d'autres lois qui précisent le fonctionnement du réflexe conditionné :

1. Le conditionnement disparaît progressivement si le stimulus conditionné est administré trop fréquemment sans le stimulus inconditionné.
2. Il arrive qu'au bout d'un certain temps, le conditionnement se rétablisse spontanément.
3. Il arrive que, par une sorte de généralisation, les effets du stimulus conditionné ou du stimulus inconditionné soient transférés à un stimulus analogue à l'un ou à l'autre.
4. La généralisation signalée en 3 peut être combattue en présentant le stimulus conditionné toujours accompagné du stimulus inconditionné et le stimulus analogue sans lui : il se produit alors une différenciation entre eux.
5. On peut créer un réflexe conditionné au deuxième degré à partir d'un réflexe conditionné.
6. L'ordre séquentiel dans lequel les stimuli conditionnés sont administrés a une influence déterminante sur la nature et l'intensité de la réponse.
7. Il est possible de combattre les effets de l'inhibition signa1ée en 1 et en 4 en associant un stimulus conditionné dont l'efficacité est en voie d'extinction ou a complètement disparu, à un nouveau stimulus.

Bien que le dressage des animaux fasse largement appel aux réflexes conditionnés, on voit aisément qu'il s'agit d'un ensemble de phénomènes beaucoup plus vaste que le simple dressage. Ce que présente Pavlov est un véritable système du fonctionnement de la pensée qui intéresse aussi bien la neurologie et la psychopathologie que les sciences de l'éducation et les sciences sociales. Il a évité l'écueil d'une interprétation mécaniste de la pensée, ce que n'a pas su faire son contemporain, rival, puis colla­borateur, Vladimir Mikhaïlovitch Bekhterev<sup id="a21">[21](#f21)</sup>, qui eut une grande influence sur le *behaviorisme* américain des années 30.

Avec sa *machina docilis*, Grey Walter a courageusement essayé d'imiter par l'électronique le modèle pavlovien. Cette machine, aussi appelée CORA (*Conditioned Reflex Analogue*), est évidemment plus complexe que les autres. Tout repose sur l'emploi de deux mémoires amortissables qui s'effacent progressivement au bout d'un laps de temps plus ou moins long. Elles sont obtenues grâce à des condensateurs dont la charge s'épuise progressivement grâce à des résistances. Quand le stimulus neutre (qui va devenir le stimulus conditionné) est appliqué, un premier condensateur se charge. Pendant les quelques secondes qu'il lui faut pour se décharger, on applique le stimulus inconditionné. La brève coïncidence de ce stimulus avec le courant provenant du premier condensateur ferme un circuit qui envoie une charge électrique vers un deuxième condensateur dont la durée d'épuisement est beaucoup plus longue. Le courant qui provient de ce deuxième condensateur ferme un circuit qui branche le stimulus neutre sur la réponse au stimulus incondi­tionné. Dès lors, ce stimulus n'est plus neutre et le réflexe conditionné est établi. 11 dure jusqu'à épuisement du deuxième condensateur à moins qu'on ne répète l'opération d'apprentissage en faisant coïncider de nouveau la rémanence du stimulus conditionné avec le stimulus incondi­tionné, ce qui recharge le deuxième condensateur.

C'est là une description très simplifiée qui ne rend pas justice à l'ingéniosité de Grey Walter. Le fait est qu'il a réussi à reproduire de manière plus ou moins grossière chacune des sept opérations décrites par Pavlov. Il a même pu créer chez sa machine une situation neurotique en associant un stimulus « agréable » (tropisme positif) à un stimulus « désagréable » (tropisme négatif). Et en ce cas il n'y a que les trois remèdes classiques de la psychiatrie: le sommeil (laisser les mémoires s'éteindre), le choc (débrancher puis rebrancher tous les circuits) et la chirurgie (déconnecter le circuit perturbateur).

Les machines rudimentaires que construisait Grey Walter dans les années 50 sont largement dépassées, et un simple ordinateur IBM 370 est capable de performances bien plus extraordinaires, mais, comme l'écrit Abraham Moles, « ces machines à manipuler la complexité traitent l'information suivant certains *modèles de simulation* »<sup id="a22">[22](#f22)</sup>. En effet, il ne s'agit pas d'autre chose que de simulation, dans le cas de la *machina docilis* : elle répète simplement le modèle rationalisé par Pavlov d'une partie des performances de l'être vivant.

Pourtant, le rêve cybernétique a la vie dure. On a été jusqu'à demander à l'ordinateur de s'attaquer à ce qu'il y a de plus spécifiquement humain dans les performances de notre cerveau : le langage littéraire. La poésie par ordinateur, cultivée notamment à Stuttgart et au Canada, est devenue une banalité. Elle n'a pas grand avenir car elle est ruineuse. Comme le dit un personnage d'un roman qui traite de ce sujet : « Le jeu n'en vaut pas la chandelle. Pensez: il serait absurde de dépenser une fortune pour produire des vers à la machine, quand il y a des poètes de génie qui vous font ça pour un quignon de pain et l'air du temps! »<sup id="a23">[23](#f23)</sup>.

Il est d'ailleurs caractéristique qu'on se soit attaqué à la poésie où la conceptualisation est secondaire, plutôt qu'à la prose où le crétinisme de la machine serait trop évident.

D'ailleurs, parmi les performances du cerveau humain, Pavlova eu la prudence et la sagesse de s'arrêter devant le langage. En 1927 il écrivait: « Bien entendu, un mot est pour un homme un stimulus condi­tionné tout autant que les autres stimuli communs aux hommes et aux animaux, mais en même temps il implique tant de choses qu'il ne se prête à aucune comparaison quantitative ou qualitative avec les réflexes conditionnés chez les animaux »<sup id="a24">[24](#f24)</sup>.

Peut-être la distinction serait-elle de nos jours moins tranchante. Il y a un mécanomorphisme de l'animal et de l'homme comme il y a un zoomorphisme de l'homme, et les frontières ne sont ni nettes, ni stables. On peut, dans une certaine mesure, expliquer l'humain par le mécanique et l'animal, mais c'est une dangereuse illusion que de voir le mécanique et l'animal à travers le prisme déformant de l'anthropomorphisme. Le rêve cybernétique s'évanouit devant l'épreuve du langage. C'est donc maintenant aux linguistes de dire leur mot.

***
<b id="f1">1</b> : W. GREY WALTER, *The Living Brain*, Londres, Duckworth, 1953.[↩](#a1)

<b id="f2">2</b> : William Ross Ashby (né en 1903) est comme Grey Walter à la fois un neurologue et un cybernéticien. C'est dans *Design for a Brain* (1952) qu'il a décrit l'homéostat. C'est un système de quatre éléments interconnectés (voir plus haut, chapitre 4, p. 50).[↩](#a2)

<b id="f3">3</b> : *The Living Brain*, *op*, *cit*., p. 77.[↩](#a3)

<b id="f4">4</b> : Konrad Lorenz, le célèbre éthologue autrichien, citant le Professeur Hediger, décrit les deux distances critiques qui déterminent le comportement d'un animal sauvage qu'on approche. A la première distance critique, l'animal prend la fuite. Si la fuite est impossible et si l'approche continue, à la deuxième distance critique, l'animal attaque.[↩](#a4)

<b id="f5">5</b> : *The Living Brain, op. cit.,* p. 84.[↩](#a5)

<b id="f6">6</b> : *Op. cir.,* p. 86.[↩](#a6)

<b id="f7">7</b> : Voir chapitre 10, pp. 170-179.[↩](#a7)

<b id="f8">8</b> : *The Living Brain, op. cit.,* p. 10.[↩](#a8)

<b id="f9">9</b> : Norbert Wiener (1894-1964) a été l'un des mathématiciens américains de sa géné­ration les plus respectés. Il obtint à Harvard son Ph, D, en 1913 à l'âge de 18 ans. II étudia la philosophie et la logique à Cambridge avec Bertrand Russell tout en s'initiant aux mathé­matiques. Il poursuivit ses études de mathématiques à Gôttingen et fut en philosophie l'élève de Husserl, Professeur de mathématiques au M.I.T. depuis 1919, il contribua lar­gement aux recherches militaires des États-Unis sur le téléguidage des projectiles, Dès 1943 il exposa les grands principes de ce qui devait devenir la cybernétique, dans un article écrit en collaboration avec ses collègues J. Bigelow et A. Rosenblueth et intitulé « Behavior, Purpose and Teleology », *Philosophy of Science*, vol. 10, nO J, pp. 18-24.[↩](#a9)

<b id="f10">10</b> : Ce livre a été réédité en 1961 par le M.l.T.[↩](#a10)

<b id="f11">11</b> : J.R. PIERCE, *Symbols , Signais and Noise*, New York, Harper, 1961, p. 209.[↩](#a11)

<b id="f12">12</b> : Publiée sous la direction de David L. Si Ils, New York, Macmillan, 1968. M.E. Ma­ron, élève de Wiener, est professeur à l'Université de Californie (Berkeley). Il a également consacré un article à Wiener dans la même encyclopédie.[↩](#a12)

<b id="f13">13</b> : Pour une vulgarisation amusante, mais bien documentée, des idées soviétiques, voir V. Pelekis, *Kibernetiketcheskaïa Smies* , Moscou, Znamié, 1970 (trad. *Mélanges cyber­nétiques*, Moscou, Mir, 1975).[↩](#a13)

<b id="f14">14</b> : C'est James Clerk Maxwell (1831-1879), physicien écossais considéré comme le père de la théorie électromagnétique de la lumière, qui a inventé ce personnage fictif alors qu'il poursuivait des recherches sur la théorie cinétique des gaz. Le démon de Maxwell est dans une boîte emplie de gaz et séparée en deux compartiments par une cloison. II ouvre à volonté la porte entre les deux compartiments pour laisser passer ou arrêter les molécules de gaz. Si l'on suppose que la fantaisie le prenne de n'ouvrir la porte qu'aux molécules « rapides » et de la fermer aux molécules « lentes », il accumulera toutes les molécules « rapides » (et donc chaudes) d'un côté et toutes les molécules « lentes » (et donc froides) de l'autre, ce qui veut dire qu'il chauffera un des compartiments en refroidissant l'autre, ce qui viole le second principe de Carnot. Dans la mesure où l'on peut imaginer un dispositif mécanique réalisant le programme du démon de Maxwell, il serait ainsi théori­quement possible de réaliser le mouvement perpétuel.[↩](#a14)

<b id="f15">15</b> : *Fool's Mate*, paru en mars 1953 dans la revue *Astounding Science Fiction Magazine*, a été réédité dans le recueil *Shards of Space*, New York, Bantam Books, 1962. Robert Sheckley, qui est considéré comme l'humoriste de la science-fiction, revient souvent sur le thème de l'ordinateur.[↩](#a15)

<b id="f16">16</b> : V. Pelekis, cité plus haut, met en épigraphe de son ouvrage cette phrase de N. Wiener: «Rendons à l'homme ce qui appartient à l'homme et à la machine ce qui appartient à la machine. »[↩](#a16)

<b id="f17">17</b> : Ce qui n'empêche pas le nombre de Shanks d'être gravé en bronze sur un des murs du Palais de la Découverte à Paris.[↩](#a17)

<b id="f18">18</b> : Un des premiers calculateurs à tubes construits après la guerre par J.P. Eckert et J.W. Mauchly.[↩](#a18)

<b id="f19">19</b> : Ivan Mikhaïlovitch Sechenov (1829-1905), d'abord officier du génie, a fait des études de médecine à Moscou, puis fit des recherches en Allemagne et en France. Professeur de pbysiologie à Odessa, Saint-Pétersbourg, puis Moscou, il fut peu connu hors de Russie jusqu'au milieu du xx· siècle où certains behavioristes américains tendent à le considérer comme un précurseur.[↩](#a19)

<b id="f20">20</b> : Ivan Petrovitch Pavlov (1849-1936), originaire de Ryazan, est une des plus presti­gieuses figures de la science russe. Après avoir fait des études de théologie, de mathématiques, de physique, il s'orienta vers la physiologie en partie sous l'influence des écrits de Sechenov, Prix Nobel de physiologie en 1904, il devint en 1907 membre de l'Académie Impériale Russe et en 1908 membre de l'Académie des Sciences des États-Unis.[↩](#a20)

<b id="f21">21</b> : Vladimir Mikhaïlovitch Bekhterev (1857-1927), né près de Kirov, fut professeur de physiologie à l'Université de Kazan, puis à l'Académie Médicale Militaire de Saint­-Pétersbourg dont il avait été l'élève. Il a fait des recherches en Allemagne et en France au laboratoire de Charcot. Il est considéré comme le fondateur de la « réflexologie ».[↩](#a21)

<b id="f22">22</b> : Abraham MOLES, *Art et Ordinateur*, Paris, Casterman, 1971, p. 56.[↩](#a22)

<b id="f23">23</b> :  R. ESCARPIT, *Le Littératron*, Paris, Flammarion, 1964, p. 86.[↩](#a23)

<b id="f24">24</b> :  I.P. PAVLOV, *Eksperimentalnaya psikhologya i psikhopatologya na jivotnikh* , Leningrad, 1928. Traduit en anglais dans *Lectures on Conditioned Reflexe*s, New York, International Publishers, pp. 59-60.[↩](#a24)
